<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Collaborative Face Experts Fusion in Video Generation: Boosting Identity Consistency Across Large Face Poses</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f8f9fa;
            line-height: 1.6;
            color: #333;
        }

        .container {
            max-width: 1000px; /*  ä» 1200px è°ƒå° */
            margin: 0 auto;
            padding: 20px;
        }

        /* Header Styles */
        .header {
            text-align: center;
            padding: 40px 0;
            color: #333; /* æ–‡å­—æ”¹ä¸ºæ·±è‰² */
            margin-bottom: 40px;
            /* ç§»é™¤åœ†è§’ */
        }

        .header h1 {
            font-size: 2.5em;
            font-weight: 700; /* è®¾ç½®ä¸ºæ ‡å‡†ç²—ä½“ */
            margin-bottom: 10px;
            line-height: 1.2;
        }

        /* Author Styles */
        .authors {
            margin: 30px 0;
            font-size: 1.0em;
            line-height: 1.8;
        }
        .author-list, .affiliation-list, .contribution-list {
            margin-bottom: 15px;
        }
        .author-list span, .affiliation-list span {
            margin: 0 10px;
        }

        /* Resource Links */
        .resource-links {
            margin-top: 30px;
            display: flex;
            justify-content: center;
            gap: 20px;
        }
        .link-button {
            display: inline-block;
            padding: 10px 25px;
            border: 1px solid #ddd;
            border-radius: 20px;
            text-decoration: none;
            color: #333;
            font-weight: 500;
            transition: all 0.3s ease;
        }
        .link-button:hover {
            background-color: #f0f0f0;
            border-color: #ccc;
        }

        .header .subtitle {
            font-size: 1.1em;
            opacity: 0.7; /* è°ƒæ•´é€æ˜åº¦ */
            color: #555;
        }

        /* Section Styles */
        .section {
            /* ç§»é™¤ background, border-radius, box-shadow, padding */
            margin-bottom: 40px; /* å¢åŠ åŒºåŸŸé—´è· */
            text-align: center; /* å±…ä¸­å…¶å†…éƒ¨æ‰€æœ‰æ ‡é¢˜ */
        }

        .section h2 {
            color: #333;
            margin-bottom: 20px;
            font-size: 2em;
            font-weight: 400;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
            display: inline-block; /* ä½¿è¾¹æ¡†è·Ÿéšæ–‡å­—å®½åº¦ */
        }

        .section h3 {
            color: #555;
            margin: 20px 0 15px 0;
            font-size: 1.3em;
            /* text-align: center; å·²ç”±çˆ¶å…ƒç´ å¤„ç† */
        }

        .section p {
            margin-bottom: 15px;
            color: #666;
            font-size: 1.05em;
            max-width: 800px; /* è®¾ç½®æ–‡æœ¬æ®µè½çš„æœ€å¤§å®½åº¦ */
            margin-left: auto;   /* å·¦å³è‡ªåŠ¨è¾¹è·ä½¿å…¶å±…ä¸­ */
            margin-right: auto;
            text-align: left; /* å°†æ®µè½æ–‡æœ¬è®¾ç½®ä¸ºå·¦å¯¹é½ */
        }

        .placeholder-content {
            background: #f8f9fa;
            border: 2px dashed #ddd;
            border-radius: 8px;
            padding: 40px;
            text-align: center;
            color: #888;
            font-style: italic;
        }

        /* Experiments Section - Video Grid */
        .video-grid {
            display: grid;
            gap: 20px 15px; /* å¢åŠ è¡Œé—´è· */
            margin-bottom: 40px; /* å¢åŠ è¡¨æ ¼ä¹‹é—´çš„è·ç¦» */
            /* ç§»é™¤ background, padding, border-radius, box-shadow */
        }

        .video-grid-6-cols {
            grid-template-columns: 120px repeat(6, 1fr);
        }

        .video-grid-3-cols {
            grid-template-columns: 120px repeat(3, 1fr);
        }

        .method-label {
            /* ç§»é™¤ background, border-radius, padding */
            font-weight: 500;
            color: #555; /* ç¨å¾®åŠ æ·±é¢œè‰² */
            text-align: center;
            align-self: end; /* æ–‡å­—åº•éƒ¨å¯¹é½ */
            padding-bottom: 5px; /* ä¸è§†é¢‘ç•™å‡ºä¸€ç‚¹ç©ºé—´ */
        }

        .method-label.featured {
            background: none; /* ç§»é™¤èƒŒæ™¯ */
            color: #667eea; /* ä½¿ç”¨ä¸»é¢˜è‰²çªå‡º */
            font-weight: 700; /* åŠ ç²— */
            position: relative;
        }

        .method-label.featured::after {
            content: ""; /* ç§»é™¤æ˜Ÿæ˜Ÿ */
        }

        .sample-header {
            /* ç§»é™¤ background, border-radius, border-left */
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 500;
            color: #555;
            text-align: center;
        }

        .video-cell {
            border-radius: 8px; /* è½»å¾®çš„åœ†è§’ */
            overflow: hidden;
            background: #f8f9fa;
            aspect-ratio: 16/9;
        }

        .video-cell video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 6px;
        }

        .video-cell:hover video {
            transform: scale(1.02);
            transition: transform 0.2s ease;
        }

        .controls {
            text-align: center;
            margin-top: 20px;
        }

        .controls button {
            background: #667eea;
            color: white;
            border: none;
            padding: 8px 16px;
            margin: 0 5px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }

        .controls button:hover {
            background: #5a67d8;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            .video-grid {
                grid-template-columns: 100px repeat(3, 1fr);
                gap: 10px;
            }
            
            .method-label, .sample-header {
                font-size: 12px;
                padding: 8px;
            }

            .section {
                padding: 20px;
            }

            .method-image {
                max-width: 80%;
            }
        }

        /* Method image styles */
        .method-image {
            display: block; /* å¼ºåˆ¶å›¾ç‰‡ä¸ºå—çº§å…ƒç´ ï¼Œä½¿å…¶æ¢è¡Œ */
            width: 100%;
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            margin: 20px auto; /* ä½¿ç”¨ auto è¾¹è·ä½¿å…¶åœ¨å—çº§çŠ¶æ€ä¸‹å±…ä¸­ */
        }
        .small-image {
            display: block;  
            max-width: 70%; 
            margin: 20px auto; /* ä½¿å›¾ç‰‡æ°´å¹³å±…ä¸­ */
        }

        /* Citation Section */
        .citation-box {
            background-color: #e9ecef;
            padding: 20px;
            border-radius: 8px;
            text-align: left;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
            max-width: 800px; /* åŒ¹é…æ®µè½å®½åº¦ */
            margin: 0 auto; /* å±…ä¸­å¼•ç”¨æ¡† */
        }

        .citation-box pre {
            white-space: pre-wrap; /* å…è®¸é•¿è¡Œè‡ªåŠ¨æ¢è¡Œ */
            word-break: break-all; /* å¼ºåˆ¶é•¿å•è¯æ¢è¡Œ */
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>Collaborative Face Experts Fusion in Video Generation: Boosting Identity
Consistency Across Large Face Poses</h1>

            <div class="authors">
                <div class="author-list">
                    <span>Yuji Wang<sup>1,*</sup></span>
                    <span>Moran Li<sup>2,*</sup></span>
                    <span>Xiaobin Hu<sup>3,*</sup></span>
                    <span>Ran Yi<sup>1</sup></span>
                    <span>Jiangning Zhang<sup>2</sup></span>
                    <span>Chengming Xu<sup>2</sup></span>
                    <br>
                    <span>Weijian Cao<sup>2</sup></span>
                    <span>Yabiao Wang<sup>2</sup></span>
                    <span>Chengjie Wang<sup>2</sup></span>
                    <span>Lizhuang Ma<sup>1,â€ </sup></span>
                </div>
                <div class="affiliation-list">
                    <span><sup>1</sup>Shanghai Jiao Tong University</span>
                    <span><sup>2</sup>Tencent Youtu Lab</span>
                    <span><sup>3</sup>National University of Singapore</span>
                </div>
                <div class="contribution-list">
                    <span><sup>*</sup>Equal contribution</span>
                    <span><sup>â€ </sup>Corresponding author</span>
                </div>
            </div>

            <div class="resource-links">
                <a href="https://arxiv.org/abs/2508.09476" target="_blank" class="link-button">ğŸ“„ Paper</a>
                <a href="https://github.com/rain152/LFA-Video-Generation" target="_blank" class="link-button">ğŸ’» Code</a>
                <a href="https://youtu.be/9YmKu79U9SM" target="_blank" class="link-button">ğŸ¥ Demo</a>
            </div>
        </div>

        <!-- Abstract Section -->
        <section class="section">
            <h2>Abstract</h2>
            <p>Current video generation models struggle with identity preservation under large face poses, primarily facing two challenges: the difficulty in exploring an effective mechanism to integrate identity features into DiT architectures, and the lack of targeted coverage of large face poses in existing open-source video datasets. To address these, we present two key innovations. First, we propose <b>Collaborative Face Experts Fusion (CoFE)</b>, which dynamically fuses complementary signals from three specialized experts within the DiT backbone: an identity expert that captures cross-pose invariant features, a semantic expert that encodes high-level visual context, and a detail expert that preserves pixel-level attributes such as skin texture and color gradients. Second, we introduce a data curation pipeline comprising three key components: Face Constraints to ensure diverse large-pose coverage, Identity Consistency to maintain stable identity across frames, and Speech Disambiguation to align textual captions with actual speaking behavior. This pipeline yields LaFID-180K, a large-scale dataset of pose-annotated video clips designed for identity-preserving video generation. Experimental results on several benchmarks demonstrate that our approach significantly outperforms state-of-the-art methods in face similarity, FID, and CLIP semantic alignment.</p>
        </section>

        <!-- Method Section -->
        <section class="section">
            <h2>Method</h2>
            <img src="assets/CoFE_pipeline.jpg" alt="Method Overview" class="method-image">
        </section>

        <!-- Dataset Section -->
        <section class="section">
            <h2>Data Process</h2>
            <img src="assets/data_process.jpg" alt="Dataset Processing Pipeline" class="small-image">
        </section>

        <!-- Experiments Section -->
        <section class="section">
            <h2>Experiments</h2>
            <h3>Visualization Comparison on LaFID-Bench and VIP-Test</h3>
            
            <div class="video-grid video-grid-3-cols">
                <!-- Header row 1 -->
                <div></div>
                <div class="method-label">CogVideoX</div>
                <div class="method-label">LTX-Video</div>
                <div class="method-label">ConsisID</div>

                <!-- Sample 1, Row 1 -->
                <div class="sample-header">Sample 1</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/CogVideoX_I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/LTX-2B.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/ConsisID.mp4" type="video/mp4">
                    </video>
                </div>

                <!-- Sample 2, Row 1 -->
                <div class="sample-header">Sample 2</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/CogVideoX_I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/LTX-2B.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/ConsisID.mp4" type="video/mp4">
                    </video>
                </div>

                <!-- Sample 3, Row 1 -->
                <div class="sample-header">Sample 3</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/CogVideoX_I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/LTX-2B.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/ConsisID.mp4" type="video/mp4">
                    </video>
                </div>
            </div>

            <div class="video-grid video-grid-3-cols">
                <!-- Header row 2 -->
                <div></div>
                <div class="method-label">Wan2.1</div>
                <div class="method-label">Wan2.2</div>
                <div class="method-label featured">Wan2.2 w/ CoFE</div>

                <!-- Sample 1, Row 2 -->
                <div class="sample-header">Sample 1</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/Wan2.1-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/Wan2.2-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo1/Wan2.2-CoFE.mp4" type="video/mp4">
                    </video>
                </div>

                <!-- Sample 2, Row 2 -->
                <div class="sample-header">Sample 2</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/Wan2.1-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/Wan2.2-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo2/Wan2.2-CoFE.mp4" type="video/mp4">
                    </video>
                </div>

                <!-- Sample 3, Row 2 -->
                <div class="sample-header">Sample 3</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/Wan2.1-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/Wan2.2-I2V.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/demo3/Wan2.2-CoFE.mp4" type="video/mp4">
                    </video>
                </div>
            </div>

            <h3>Visualization Comparison with Closed-Source Models</h3>
            <div class="video-grid video-grid-3-cols">
                <!-- Header row -->
                <div></div>
                <div class="method-label">Kling 1.6</div>
                <div class="method-label">Vidu 1.5</div>
                <div class="method-label featured">Wan2.2 w/ CoFE</div>
                
                <div class="sample-header">Sample 1</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/kling/sample1.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/vidu/sample1.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/ours/sample1.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="sample-header">Sample 2</div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/kling/sample2.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/vidu/sample2.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="video-cell">
                    <video controls loop muted playsinline>
                        <source src="videos/closed_model/ours/sample2.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </section>

        <!-- Citation Section -->
        <section class="section">
            <h2>Citation</h2>
            <div class="citation-box">
                <pre><code>@article{wang2025large,
  title={From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts},
  author={Wang, Yuji and Li, Moran and Hu, Xiaobin and Yi, Ran and Zhang, Jiangning and Xu, Chengming and Cao, Weijian and Wang, Yabiao and Wang, Chengjie and Ma, Lizhuang},
  journal={arXiv e-prints},
  pages={arXiv--2508},
  year={2025}
}</code></pre>
            </div>
        </section>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const videos = document.querySelectorAll("video");

            const options = {
                root: null, // ä½¿ç”¨æµè§ˆå™¨è§†å£ä½œä¸ºæ ¹
                rootMargin: "0px",
                threshold: 0.5 // è§†é¢‘è‡³å°‘ 50% å¯è§æ—¶è§¦å‘
            };

            const observer = new IntersectionObserver((entries, observer) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        // å…ƒç´ è¿›å…¥è§†å£ï¼Œæ’­æ”¾è§†é¢‘
                        entry.target.play();
                    } else {
                        // å…ƒç´ ç¦»å¼€è§†å£ï¼Œæš‚åœè§†é¢‘
                        entry.target.pause();
                    }
                });
            }, options);

            // è§‚å¯Ÿé¡µé¢ä¸Šçš„æ¯ä¸€ä¸ªè§†é¢‘
            videos.forEach(video => {
                observer.observe(video);
            });
        });
    </script>
</body>
</html>